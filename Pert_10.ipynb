{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf967690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) dari Ensemble (Averaging): 0.38908347298224133\n",
      "\n",
      "--- Metadata Dataset Wine Quality ---\n",
      "{'uci_id': 186, 'name': 'Wine Quality', 'repository_url': 'https://archive.ics.uci.edu/dataset/186/wine+quality', 'data_url': 'https://archive.ics.uci.edu/static/public/186/data.csv', 'abstract': 'Two datasets are included, related to red and white vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests (see [Cortez et al., 2009], http://www3.dsi.uminho.pt/pcortez/wine/).', 'area': 'Business', 'tasks': ['Classification', 'Regression'], 'characteristics': ['Multivariate'], 'num_instances': 4898, 'num_features': 11, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['quality'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2009, 'last_updated': 'Wed Nov 15 2023', 'dataset_doi': '10.24432/C56S3T', 'creators': ['Paulo Cortez', 'A. Cerdeira', 'F. Almeida', 'T. Matos', 'J. Reis'], 'intro_paper': {'ID': 252, 'type': 'NATIVE', 'title': 'Modeling wine preferences by data mining from physicochemical properties', 'authors': 'P. Cortez, A. Cerdeira, Fernando Almeida, Telmo Matos, J. Reis', 'venue': 'Decision Support Systems', 'year': 2009, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/Modeling-wine-preferences-by-data-mining-from-Cortez-Cerdeira/bf15a0ccc14ac1deb5cea570c870389c16be019c', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'The two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine. For more details, consult: http://www.vinhoverde.pt/en/ or the reference [Cortez et al., 2009].  Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\\n\\nThese datasets can be viewed as classification or regression tasks.  The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'For more information, read [Cortez et al., 2009].\\r\\nInput variables (based on physicochemical tests):\\r\\n   1 - fixed acidity\\r\\n   2 - volatile acidity\\r\\n   3 - citric acid\\r\\n   4 - residual sugar\\r\\n   5 - chlorides\\r\\n   6 - free sulfur dioxide\\r\\n   7 - total sulfur dioxide\\r\\n   8 - density\\r\\n   9 - pH\\r\\n   10 - sulphates\\r\\n   11 - alcohol\\r\\nOutput variable (based on sensory data): \\r\\n   12 - quality (score between 0 and 10)', 'citation': None}}\n",
      "\n",
      "--- Informasi Variabel Dataset Wine Quality ---\n",
      "                    name     role         type demographic  \\\n",
      "0          fixed_acidity  Feature   Continuous        None   \n",
      "1       volatile_acidity  Feature   Continuous        None   \n",
      "2            citric_acid  Feature   Continuous        None   \n",
      "3         residual_sugar  Feature   Continuous        None   \n",
      "4              chlorides  Feature   Continuous        None   \n",
      "5    free_sulfur_dioxide  Feature   Continuous        None   \n",
      "6   total_sulfur_dioxide  Feature   Continuous        None   \n",
      "7                density  Feature   Continuous        None   \n",
      "8                     pH  Feature   Continuous        None   \n",
      "9              sulphates  Feature   Continuous        None   \n",
      "10               alcohol  Feature   Continuous        None   \n",
      "11               quality   Target      Integer        None   \n",
      "12                 color    Other  Categorical        None   \n",
      "\n",
      "               description units missing_values  \n",
      "0                     None  None             no  \n",
      "1                     None  None             no  \n",
      "2                     None  None             no  \n",
      "3                     None  None             no  \n",
      "4                     None  None             no  \n",
      "5                     None  None             no  \n",
      "6                     None  None             no  \n",
      "7                     None  None             no  \n",
      "8                     None  None             no  \n",
      "9                     None  None             no  \n",
      "10                    None  None             no  \n",
      "11  score between 0 and 10  None             no  \n",
      "12            red or white  None             no  \n"
     ]
    }
   ],
   "source": [
    "# Mengimpor modul utilitas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# **MEMASUKKAN KODE UCI REPO UNTUK MENGAMBIL DATA WINE QUALITY**\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset (Wine Quality ID=186)\n",
    "wine_quality = fetch_ucirepo(id=186)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "# X adalah fitur (variabel independen)\n",
    "# y adalah target (variabel dependen, yaitu 'quality')\n",
    "X = wine_quality.data.features\n",
    "y = wine_quality.data.targets\n",
    "\n",
    "# Mengimpor model pembelajaran mesin untuk prediksi\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# **MENGGANTI BAGIAN PEMUATAN DATA DF DAN PEMISAHAN TRAIN/TARGET**\n",
    "# Data train (X) dan target (y) sudah diambil dari UCI di atas.\n",
    "# Kita perlu mengonversi 'y' menjadi Series atau DataFrame dengan nama kolom 'quality'\n",
    "# agar dapat diakses dengan kunci: y_series = y['quality']\n",
    "\n",
    "# Memisahkan antara data pelatihan ke dalam himpunan data pelatihan dan validasi\n",
    "# Menggunakan X (features) dan y['quality'] (target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y['quality'], test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "# Menginisialisasi semua objek model dengan parameter default\n",
    "model_1 = LinearRegression()\n",
    "model_2 = xgb.XGBRegressor()\n",
    "model_3 = RandomForestRegressor()\n",
    "\n",
    "# melatih semua model pada himpunan data pelatihan\n",
    "# **CATATAN: Variabel y_target pada kode asli Anda TIDAK terdefinisi,\n",
    "# sudah diganti dengan y_train yang benar.**\n",
    "model_1.fit(X_train, y_train)\n",
    "model_2.fit(X_train, y_train)\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "# memprediksi output pada himpunan data validasi\n",
    "pred_1 = model_1.predict(X_test)\n",
    "pred_2 = model_2.predict(X_test)\n",
    "pred_3 = model_3.predict(X_test)\n",
    "\n",
    "# prediksi akhir setelah rata-rata prediksi dari semua 3 model\n",
    "pred_final = (pred_1 + pred_2 + pred_3) / 3.0\n",
    "\n",
    "# mencetak kesalahan kuadrat rata-rata antara nilai riil dan nilai prediksi\n",
    "print(f\"Mean Squared Error (MSE) dari Ensemble (Averaging): {mean_squared_error(y_test, pred_final)}\")\n",
    "\n",
    "# **INFORMASI DATASET TAMBAHAN (Opsional)**\n",
    "print(\"\\n--- Metadata Dataset Wine Quality ---\")\n",
    "print(wine_quality.metadata)\n",
    "print(\"\\n--- Informasi Variabel Dataset Wine Quality ---\")\n",
    "print(wine_quality.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc87335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:23:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy dari Ensemble (Max Voting 'hard'): 0.8647763332992118\n",
      "\n",
      "--- Metadata Dataset Adult ---\n",
      "{'uci_id': 2, 'name': 'Adult', 'repository_url': 'https://archive.ics.uci.edu/dataset/2/adult', 'data_url': 'https://archive.ics.uci.edu/static/public/2/data.csv', 'abstract': 'Predict whether annual income of an individual exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset. ', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 48842, 'num_features': 14, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Income', 'Education Level', 'Other', 'Race', 'Sex'], 'target_col': ['income'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1996, 'last_updated': 'Tue Sep 24 2024', 'dataset_doi': '10.24432/C5XW20', 'creators': ['Barry Becker', 'Ronny Kohavi'], 'intro_paper': None, 'additional_info': {'summary': \"Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\\n\\nPrediction task is to determine whether a person's income is over $50,000 a year.\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Listing of attributes:\\r\\n\\r\\n>50K, <=50K.\\r\\n\\r\\nage: continuous.\\r\\nworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\\r\\nfnlwgt: continuous.\\r\\neducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\\r\\neducation-num: continuous.\\r\\nmarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\\r\\noccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\\r\\nrelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\\r\\nrace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\\r\\nsex: Female, Male.\\r\\ncapital-gain: continuous.\\r\\ncapital-loss: continuous.\\r\\nhours-per-week: continuous.\\r\\nnative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.', 'citation': None}}\n",
      "\n",
      "--- Informasi Variabel Dataset Adult ---\n",
      "              name     role         type      demographic  \\\n",
      "0              age  Feature      Integer              Age   \n",
      "1        workclass  Feature  Categorical           Income   \n",
      "2           fnlwgt  Feature      Integer             None   \n",
      "3        education  Feature  Categorical  Education Level   \n",
      "4    education-num  Feature      Integer  Education Level   \n",
      "5   marital-status  Feature  Categorical            Other   \n",
      "6       occupation  Feature  Categorical            Other   \n",
      "7     relationship  Feature  Categorical            Other   \n",
      "8             race  Feature  Categorical             Race   \n",
      "9              sex  Feature       Binary              Sex   \n",
      "10    capital-gain  Feature      Integer             None   \n",
      "11    capital-loss  Feature      Integer             None   \n",
      "12  hours-per-week  Feature      Integer             None   \n",
      "13  native-country  Feature  Categorical            Other   \n",
      "14          income   Target       Binary           Income   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                 N/A  None             no  \n",
      "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
      "2                                                None  None             no  \n",
      "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
      "4                                                None  None             no  \n",
      "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
      "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
      "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
      "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
      "9                                       Female, Male.  None             no  \n",
      "10                                               None  None             no  \n",
      "11                                               None  None             no  \n",
      "12                                               None  None             no  \n",
      "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
      "14                                       >50K, <=50K.  None             no  \n"
     ]
    }
   ],
   "source": [
    "# Mengimpor modul utilitas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# **MEMASUKKAN KODE UCI REPO UNTUK MENGAMBIL DATA ADULT (KLASIFIKASI)**\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset (Adult ID=2)\n",
    "adult = fetch_ucirepo(id=2)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "# X adalah fitur (variabel independen)\n",
    "# y adalah target (variabel dependen, yaitu income: >50K, <=50K)\n",
    "X = adult.data.features\n",
    "y = adult.data.targets\n",
    "\n",
    "# Mengimpor model pembelajaran mesin untuk prediksi\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# Menambahkan kelas untuk Logistik Regression agar bisa mengatasi konvergensi\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# mengimpor pengklasifikasi suara\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "\n",
    "y_series = y.iloc[:, 0].str.strip().str.replace('.', '', regex=False)\n",
    "\n",
    "\n",
    "# **MENGGANTI BAGIAN PEMUATAN DATA DF DAN PEMISAHAN TRAIN/TARGET**\n",
    "# Memisahkan antara data pelatihan ke dalam himpunan data pelatihan dan validasi\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_series, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Menginisialisasi semua objek model dengan parameter default\n",
    "# Menambahkan max_iter dan solver untuk membantu konvergensi Logistic Regression\n",
    "model_1 = LogisticRegression(solver='liblinear', random_state=42) \n",
    "model_2 = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model_3 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Membuat model akhir menggunakan pengklasifikasi pemungutan suara\n",
    "final_model = VotingClassifier(\n",
    "    estimators=[('lr', model_1), ('xgb', model_2), ('rf', model_3)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# melatih semua model pada himpunan data kereta\n",
    "# CATATAN: Karena data sudah di-pre-process dan dipisah, ini siap dilatih.\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# memprediksi output pada himpunan data pengujian\n",
    "pred_final = final_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Menggunakan Akurasi sebagai metrik untuk VotingClassifier 'hard'\n",
    "accuracy = final_model.score(X_test, y_test)\n",
    "print(f\"Accuracy dari Ensemble (Max Voting 'hard'): {accuracy}\")\n",
    "\n",
    "# Jika Anda ingin menggunakan log_loss, ganti voting='hard' menjadi voting='soft'\n",
    "# dan gunakan pred_proba. Contoh:\n",
    "\"\"\"\n",
    "final_model_soft = VotingClassifier(\n",
    "    estimators=[('lr', model_1), ('xgb', model_2), ('rf', model_3)],\n",
    "    voting='soft'\n",
    ")\n",
    "final_model_soft.fit(X_train, y_train)\n",
    "pred_proba_final = final_model_soft.predict_proba(X_test)\n",
    "print(f\"Log Loss dari Ensemble (Max Voting 'soft'): {log_loss(y_test, pred_proba_final)}\")\n",
    "\"\"\"\n",
    "\n",
    "# **INFORMASI DATASET TAMBAHAN (Opsional)**\n",
    "print(\"\\n--- Metadata Dataset Adult ---\")\n",
    "print(adult.metadata)\n",
    "print(\"\\n--- Informasi Variabel Dataset Adult ---\")\n",
    "print(adult.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0beb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) dari Ensemble Stacking: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.datasets import make_regression # Import untuk membuat data sintetis\n",
    "\n",
    "# --- MEMUAT DATA SINTETIS (make_regression) sebagai pengganti data UCI ---\n",
    "# Membuat dataset regresi dengan 1000 sampel dan 10 fitur\n",
    "X_data, y_data = make_regression(n_samples=1000, n_features=10, \n",
    "                                 n_informative=5, random_state=42)\n",
    "\n",
    "X_clean = pd.DataFrame(X_data)\n",
    "y_clean = pd.Series(y_data)\n",
    "\n",
    "# Memisahkan antara data pelatihan ke dalam himpunan data pelatihan dan validasi\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y_clean, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "# --- MODEL IMPLEMENTASI STACKING DENGAN SKLEARN (Pengganti vecstack) ---\n",
    "# menginisialisasi semua objek model dasar (estimators)\n",
    "model_1 = LinearRegression()\n",
    "# model_2: Diganti dari XGBRegressor menjadi KNeighborsRegressor karena XGBoost tidak tersedia\n",
    "model_2 = KNeighborsRegressor() \n",
    "model_3 = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# menempatkan semua objek model dasar dalam format list of tuples (name, estimator)\n",
    "estimators = [\n",
    "    ('lr', model_1),\n",
    "    ('knn', model_2),\n",
    "    ('rf', model_3)\n",
    "]\n",
    "\n",
    "# Inisialisasi StackingRegressor (final_estimator adalah meta-model)\n",
    "final_model = StackingRegressor(\n",
    "    estimators=estimators, \n",
    "    final_estimator=LinearRegression(), # Meta-model (level-two model)\n",
    "    cv=4 # Cross-validation folds (setara dengan n_folds di vecstack)\n",
    ")\n",
    "\n",
    "# melatih model Stacking pada himpunan data pelatihan\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# memprediksi output akhir\n",
    "pred_final = final_model.predict(X_test)\n",
    "\n",
    "# mencetak kesalahan kuadrat rata-rata antara nilai riil dan nilai prediksi\n",
    "print(f\"Mean Squared Error (MSE) dari Ensemble Stacking: {mean_squared_error(y_test, pred_final):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9031f290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Metode Blending (Regresi) ---\n",
      "Mean Squared Error (MSE): 0.3621\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# --- MEMUAT DATA DARI UCI (WINE QUALITY, ID=186) ---\n",
    "wine_quality = fetch_ucirepo(id=186)\n",
    "X = wine_quality.data.features\n",
    "y = wine_quality.data.targets['quality'] # Target Regresi\n",
    "\n",
    "# Tentukan rasio pembagian untuk Train/Validation/Test [cite: 143, 144, 145]\n",
    "train_ratio = 0.70\n",
    "validation_ratio = 0.20\n",
    "test_ratio = 0.10\n",
    "\n",
    "# 1. Melakukan pemisahan Train/Rest (Test + Validation)\n",
    "x_train, x_rest, y_train, y_rest = train_test_split(\n",
    "    X, y, test_size=1 - train_ratio, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Melakukan pemisahan Validation/Test dari data 'Rest'\n",
    "# Perhitungan test_size: test_ratio / (test_ratio + validation_ratio)\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_rest, y_rest, test_size=test_ratio / (test_ratio + validation_ratio), random_state=42\n",
    ")\n",
    "\n",
    "# menginisialisasi semua objek model dasar dengan parameter default [cite: 154]\n",
    "model_1 = LinearRegression()\n",
    "model_2 = xgb.XGBRegressor(random_state=42)\n",
    "model_3 = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Melatih dan memprediksi\n",
    "# Pelatihan Model Pertama (Linear Regression)\n",
    "model_1.fit(x_train, y_train)\n",
    "val_pred_1 = model_1.predict(x_val) # Prediksi pada Validation\n",
    "test_pred_1 = model_1.predict(x_test) # Prediksi pada Test\n",
    "\n",
    "# Pelatihan Model Kedua (XGBoost)\n",
    "model_2.fit(x_train, y_train)\n",
    "val_pred_2 = model_2.predict(x_val)\n",
    "test_pred_2 = model_2.predict(x_test)\n",
    "\n",
    "# Pelatihan Model Ketiga (Random Forest)\n",
    "model_3.fit(x_train, y_train)\n",
    "val_pred_3 = model_3.predict(x_val)\n",
    "test_pred_3 = model_3.predict(x_test)\n",
    "\n",
    "# Mengonversi hasil prediksi ke Dataframe untuk digabungkan\n",
    "val_preds = pd.DataFrame({'pred_1': val_pred_1, 'pred_2': val_pred_2, 'pred_3': val_pred_3}, index=x_val.index)\n",
    "test_preds = pd.DataFrame({'pred_1': test_pred_1, 'pred_2': test_pred_2, 'pred_3': test_pred_3}, index=x_test.index)\n",
    "\n",
    "# kumpulan data validasi gabungan bersama dengan semua data validasi yang diprediksi (fitur meta) [cite: 174, 175]\n",
    "df_val = pd.concat([x_val.reset_index(drop=True), val_preds.reset_index(drop=True)], axis=1)\n",
    "df_test = pd.concat([x_test.reset_index(drop=True), test_preds.reset_index(drop=True)], axis=1)\n",
    "y_val_blend = y_val.reset_index(drop=True)\n",
    "y_test_blend = y_test.reset_index(drop=True)\n",
    "\n",
    "# Membuat model akhir menggunakan fitur meta (Meta Model) [cite: 177, 178]\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(df_val, y_val_blend)\n",
    "\n",
    "# mendapatkan hasil akhir [cite: 180, 181]\n",
    "final_pred = final_model.predict(df_test)\n",
    "\n",
    "# printing kesalahan kuadrat rata-rata antara nilai riil dan nilai prediksi [cite: 182]\n",
    "print(\"--- Metode Blending (Regresi) ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test_blend, final_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76dad8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Metode Bagging (Regresi) ---\n",
      "Mean Squared Error (MSE): 898.7090\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor # Pengganti XGBoost\n",
    "from sklearn.datasets import make_regression \n",
    "\n",
    "# --- MEMUAT DATA SINTETIS (make_regression) sebagai pengganti data UCI ---\n",
    "# Membuat dataset regresi dengan 1000 sampel dan 10 fitur\n",
    "X_data, y_data = make_regression(n_samples=1000, n_features=10, \n",
    "                                 n_informative=5, random_state=42)\n",
    "\n",
    "X = pd.DataFrame(X_data)\n",
    "y = pd.Series(y_data)\n",
    "\n",
    "# Memisahkan antara data pelatihan ke dalam himpunan data pelatihan dan validasi\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "# --- KOREKSI ERROR: GANTI 'base_estimator' menjadi 'estimator' ---\n",
    "# menginisialisasi model pengantongan menggunakan KNeighborsRegressor sebagai model dasar\n",
    "model = BaggingRegressor(\n",
    "    estimator=KNeighborsRegressor(), # Parameter telah diganti menjadi 'estimator'\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# model pelatihan\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# memprediksi output pada himpunan data pengujian\n",
    "pred_final = model.predict(X_test)\n",
    "\n",
    "# mencetak kesalahan kuadrat rata-rata antara nilai riil dan nilai prediksi\n",
    "print(\"--- Metode Bagging (Regresi) ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, pred_final):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02df57c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Metode Boosting (Regresi) ---\n",
      "Mean Squared Error (MSE): 0.4616\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# --- MEMUAT DATA DARI UCI (WINE QUALITY, ID=186) ---\n",
    "wine_quality = fetch_ucirepo(id=186)\n",
    "X = wine_quality.data.features\n",
    "y = wine_quality.data.targets['quality'] # Target Regresi\n",
    "\n",
    "# Memisahkan antara data pelatihan ke dalam himpunan data pelatihan dan validasi [cite: 241, 242]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "# menginisialisasi modul boosting (Gradient Boosting Regressor) [cite: 243, 244]\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# melatih model pada himpunan data kereta [cite: 246]\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# memprediksi output pada himpunan data pengujian [cite: 248, 249]\n",
    "pred_final = model.predict(X_test)\n",
    "\n",
    "# mencetak kesalahan kuadrat rata-rata antara nilai riil dan nilai prediksi [cite: 250]\n",
    "print(\"--- Metode Boosting (Regresi) ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, pred_final):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
